[
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "MADA Data Analysis Project",
    "section": "",
    "text": "Write a summary of your project."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "MADA Data Analysis Project",
    "section": "2.1 General Background Information",
    "text": "2.1 General Background Information\nProvide enough background on your topic that others can understand the why and how of your analysis"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "MADA Data Analysis Project",
    "section": "2.2 Description of data and data source",
    "text": "2.2 Description of data and data source\nDescribe what the data is, what it contains, where it is from, etc. Eventually this might be part of a methods section."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "title": "MADA Data Analysis Project",
    "section": "2.3 Questions/Hypotheses to be addressed",
    "text": "2.3 Questions/Hypotheses to be addressed"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "title": "MADA Data Analysis Project",
    "section": "3.1 Data aquisition",
    "text": "3.1 Data aquisition"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "MADA Data Analysis Project",
    "section": "3.2 Data import and cleaning",
    "text": "3.2 Data import and cleaning"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "MADA Data Analysis Project",
    "section": "3.3 Statistical analysis",
    "text": "3.3 Statistical analysis\nExplain anything related to your statistical analyses."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "title": "MADA Data Analysis Project",
    "section": "4.1 Exploratory/Descriptive analysis",
    "text": "4.1 Exploratory/Descriptive analysis\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nfactor.ordered\nfactor.n_unique\nfactor.top_counts\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nEduc\n0\n1\n7\n13\n0\n4\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nfactor\nGender\n0\n1\nNA\nNA\nNA\nNA\nNA\nFALSE\n3\nM: 4, F: 3, O: 2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nHeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n165.66667\n15.97655\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nnumeric\nWeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n70.11111\n21.24526\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nnumeric\nage\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n41.66667\n13.39776\n22\n34\n45\n54\n56\n▃▂▂▂▇"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "title": "MADA Data Analysis Project",
    "section": "4.2 Basic statistical analysis",
    "text": "4.2 Basic statistical analysis\nFigure1: shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\nThe scatter shows a slight postive increase in the weight of individuals with increasing age.\n\n\n\n\nFigure2: shows a Boxplot of Height and Education Levels.\n\n\n\n\n\nThe figure shows a box-plot of heights of individuals stratified by education levels."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "title": "MADA Data Analysis Project",
    "section": "4.3 Full analysis",
    "text": "4.3 Full analysis\nTable2: shows a summary of a linear model fit .\n\n\n\nGraduate, High school, and Undergraduate do not appear to be statistically significant as their p-values are higher than 0.05, Height of individuals increases by approximately by 1.08cm per one year increase in age.\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116.7253978\n14.9101494\n7.8285867\n0.0014375\n\n\nage\n1.0822039\n0.2607536\n4.1502937\n0.0142569\n\n\nEducGraduate\n0.4293852\n8.7286474\n0.0491926\n0.9631241\n\n\nEducHigh school\n10.2923787\n8.5648274\n1.2017030\n0.2957598\n\n\nEducUndergraduate\n2.4796700\n11.7223156\n0.2115341\n0.8428112"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#code-used-for-the-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#code-used-for-the-analysis",
    "title": "MADA Data Analysis Project",
    "section": "4.4 Code used for the analysis",
    "text": "4.4 Code used for the analysis\n\n##############################################\n### Box Plot\nb1&lt;-mydata %&gt;%\n  ggplot(mapping = aes(x = `Educ`, y = Height, fill = `Educ`)) +\n  geom_boxplot() +\n  scale_fill_manual(values = c(\"College\" = \"#1f78b4\", \"High school\" = \"#33a02c\", \"Graduate\" = \"#e31a1c\", \"Undergraduate\" = \"#ff7f00\")) +\n  theme_minimal() +\n  labs(x = \"Education levels\", y = \"Height\") +\n  ggtitle(\"Boxplot of Education Levels by Height\") +\n  theme(plot.title = element_text(hjust = 0.5))  # Adjust title alignment\nb1\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"education-Height-stratified.png\")\nggsave(filename = figure_file, plot=b1)\n##############################################\nFor the scatter Plot\ns1 &lt;- ggplot(mydata, aes(x = Weight, y = age)) +\n  geom_point() +\n  stat_smooth(method = \"glm\", formula = y ~ x) +\n  ggtitle(\"Scatterplot of Weight vs Age\") +\n  labs(x = \"Weight\", y = \"Age\")\ns1\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"Weight-Age-stratified.png\")\nggsave(filename = figure_file, plot=s1)\n\n############################\n#### Third model fit\n# fit linear model using height as outcome, age and Educatinal Levels as predictor\n\nlmfit3 &lt;- lm(Height ~ age + Educ, mydata)  \n\n# place results from fit into a data frame with the tidy function\nlmtable3 &lt;- broom::tidy(lmfit3)\n\n#look at fit results\nprint(lmtable3)\n\n# save fit results table  \ntable_file3 = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"resulttable3.rds\")\nsaveRDS(lmtable3, file = table_file3)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "title": "MADA Data Analysis Project",
    "section": "5.1 Summary and Interpretation",
    "text": "5.1 Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "title": "MADA Data Analysis Project",
    "section": "5.2 Strengths and Limitations",
    "text": "5.2 Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "title": "MADA Data Analysis Project",
    "section": "5.3 Conclusions",
    "text": "5.3 Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper (Leek & Peng, 2015) discusses types of analyses.\nThese papers (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, Shen, & Handel, 2020) are good examples of papers published using a fully reproducible setup similar to the one shown in this template."
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Presentation Exercise",
    "section": "",
    "text": "The data was about the poll that was conducted from Sept. 15 to Sept. 25 among a sample of U.S. citizens that oversampled young, Black and Hispanic respondents, with 8,327 respondents, and was weighted according to general population benchmarks for U.S. citizens from the U.S.\nThis the original Image to be reproduced\n\nPrompted chatgpt for the code: Prompt: Please generate R code to visualize demographic data, including variables such as race, income, age, and education, segmented by voter category. Ensure that each variable is plotted as a bar graph with custom colors for the voter categories and arrange the plots in a grid with two columns. After I adjusted the code to try fit what I wanted.\n\n# Suppress warnings while loading libraries\nsuppressPackageStartupMessages({\n  library(flextable)\n  library(ggplot2)\n  library(gridExtra)\n  library(readr)\n  library(dplyr)\n  library(patchwork)\n})\n\nWarning: package 'flextable' was built under R version 4.3.3\n\n# Read the CSV file without displaying column types\nsuppressMessages({\n  nonvoters &lt;- read_csv(\"nonvoters_data.csv\", show_col_types = FALSE)\n})\n\n\n# Create a new categorical variable 'Age_Category' based on age ranges using mutate and ifelse\nnonvoters &lt;- nonvoters %&gt;%\n  mutate(Age = ifelse(ppage &gt;= 26 & ppage &lt;= 34, \"26-34\",\n                               ifelse(ppage &gt;= 35 & ppage &lt;= 49, \"35-49\",\n                                      ifelse(ppage &gt;= 50 & ppage &lt;= 64, \"50-64\", \"65+\"))))\n\n# creating new labels for the party ID represented by Q30\nnonvoters &lt;- nonvoters %&gt;%\n  mutate(Q30 = case_when(\n    Q30 == 1 ~ \"DEMOCRATIC\",\n    Q30 == 2 ~ \"REPUBLICAN\",\n    Q30 == 3 ~ \"INDEPENDENT\",\n    TRUE ~ as.character(Q30)\n  ))\n\n\n# Define custom colors for voter categories\ncustom_colors &lt;- c(\"#ffbc00\", \"#e082ad\", \"#ae4dff\")\n\n# Plot race by voter category\nplot_race &lt;- ggplot(nonvoters, aes(x = race, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Race\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Race\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot income by voter category\nplot_income &lt;- ggplot(nonvoters, aes(x = income_cat, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Income\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Income\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot Age by voter category\nplot_age &lt;- ggplot(nonvoters, aes(x = Age, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Age\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Age\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot education by voter category\nplot_education &lt;- ggplot(nonvoters, aes(x = educ, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Education\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Education\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot party id by voter category\nplot_party &lt;- ggplot(nonvoters, aes(x = Q30, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Party ID\", y = \"Percentage\", fill = \"\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n theme(legend.position = \"bottom\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Party ID\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Arrange plots in a grid\nggpubr::ggarrange   (plot_race + theme(aspect.ratio = 1),\n          plot_income + theme(aspect.ratio = 1),\n          plot_age + theme(aspect.ratio = 1),\n          plot_education + theme(aspect.ratio = 1),\n          plot_party + theme(aspect.ratio = 1))\n\n\n\n\n\n\n\n\nNonvoters were more likely to have lower incomes; to be young; to have lower levels of education.\n\n# Read WNBA player stats data from CSV file\nsuppressWarnings(wnba_player_stats &lt;- read_csv(\"wnba-player-stats.csv\", show_col_types = FALSE))"
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html#about-data",
    "href": "presentation-exercise/presentation-exercise.html#about-data",
    "title": "Presentation Exercise",
    "section": "",
    "text": "The data was about the poll that was conducted from Sept. 15 to Sept. 25 among a sample of U.S. citizens that oversampled young, Black and Hispanic respondents, with 8,327 respondents, and was weighted according to general population benchmarks for U.S. citizens from the U.S.\nThis the original Image to be reproduced\n\nPrompted chatgpt for the code: Prompt: Please generate R code to visualize demographic data, including variables such as race, income, age, and education, segmented by voter category. Ensure that each variable is plotted as a bar graph with custom colors for the voter categories and arrange the plots in a grid with two columns. After I adjusted the code to try fit what I wanted.\n\n# Suppress warnings while loading libraries\nsuppressPackageStartupMessages({\n  library(flextable)\n  library(ggplot2)\n  library(gridExtra)\n  library(readr)\n  library(dplyr)\n  library(patchwork)\n})\n\nWarning: package 'flextable' was built under R version 4.3.3\n\n# Read the CSV file without displaying column types\nsuppressMessages({\n  nonvoters &lt;- read_csv(\"nonvoters_data.csv\", show_col_types = FALSE)\n})\n\n\n# Create a new categorical variable 'Age_Category' based on age ranges using mutate and ifelse\nnonvoters &lt;- nonvoters %&gt;%\n  mutate(Age = ifelse(ppage &gt;= 26 & ppage &lt;= 34, \"26-34\",\n                               ifelse(ppage &gt;= 35 & ppage &lt;= 49, \"35-49\",\n                                      ifelse(ppage &gt;= 50 & ppage &lt;= 64, \"50-64\", \"65+\"))))\n\n# creating new labels for the party ID represented by Q30\nnonvoters &lt;- nonvoters %&gt;%\n  mutate(Q30 = case_when(\n    Q30 == 1 ~ \"DEMOCRATIC\",\n    Q30 == 2 ~ \"REPUBLICAN\",\n    Q30 == 3 ~ \"INDEPENDENT\",\n    TRUE ~ as.character(Q30)\n  ))\n\n\n# Define custom colors for voter categories\ncustom_colors &lt;- c(\"#ffbc00\", \"#e082ad\", \"#ae4dff\")\n\n# Plot race by voter category\nplot_race &lt;- ggplot(nonvoters, aes(x = race, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Race\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Race\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot income by voter category\nplot_income &lt;- ggplot(nonvoters, aes(x = income_cat, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Income\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Income\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot Age by voter category\nplot_age &lt;- ggplot(nonvoters, aes(x = Age, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Age\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Age\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot education by voter category\nplot_education &lt;- ggplot(nonvoters, aes(x = educ, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Education\", y = \"Percentage\", fill = \"Voter Category\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n  theme(legend.position = \"\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Education\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot party id by voter category\nplot_party &lt;- ggplot(nonvoters, aes(x = Q30, fill = voter_category)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Party ID\", y = \"Percentage\", fill = \"\") +\n  scale_fill_manual(values = custom_colors) +\n  theme_minimal() +\n theme(legend.position = \"bottom\", axis.title.y = element_blank(), axis.title.x = element_blank()) +\n  coord_flip() +\n  ggtitle(\"Party ID\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Arrange plots in a grid\nggpubr::ggarrange   (plot_race + theme(aspect.ratio = 1),\n          plot_income + theme(aspect.ratio = 1),\n          plot_age + theme(aspect.ratio = 1),\n          plot_education + theme(aspect.ratio = 1),\n          plot_party + theme(aspect.ratio = 1))\n\n\n\n\n\n\n\n\nNonvoters were more likely to have lower incomes; to be young; to have lower levels of education.\n\n# Read WNBA player stats data from CSV file\nsuppressWarnings(wnba_player_stats &lt;- read_csv(\"wnba-player-stats.csv\", show_col_types = FALSE))"
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html#about-data-1",
    "href": "presentation-exercise/presentation-exercise.html#about-data-1",
    "title": "Presentation Exercise",
    "section": "About Data",
    "text": "About Data\nThe data used contains season-level advanced stats for WNBA players by team for the 1997-2019 seasons, from Basketball-Reference.com. It also contains Composite Rating, which blends PER and Win Shares per 40 into a single metric that mimics RAPTOR player ratings. I prompted chatgpt that produced a code, I didn’t use it but it guided to write mine.\nThe original table to be reproduced. \n\n# Filter the data to include only players who played at least 375 minutes\nfiltered_data &lt;- wnba_player_stats %&gt;%\n  filter(MP &gt;= 375)\n\n# Renaming variables to fit the table \nfiltered_data &lt;- filtered_data %&gt;%\n  rename(\n    PLAYER = Player,\n    SEASON = year_ID,\n    AGE = Age,\n    TEAM = Tm,\n    WS40 = WS40,\n    COMPOSITE_RATING = Composite_Rating\n  )\n# Arrange the data to find the best single-season composite ratings\ntop_players &lt;- filtered_data %&gt;%\n  arrange(desc(COMPOSITE_RATING)) %&gt;%\n  select(PLAYER, SEASON, AGE, TEAM, PER, WS40, COMPOSITE_RATING) %&gt;%\n  head(15)\n\n# Create flextable for the top players\nft &lt;- flextable(top_players)\n\n# Print the flextable\nft\n\nPLAYERSEASONAGETEAMPERWS40COMPOSITE_RATINGLauren Jackson2,00625SEA34.70.41611.5Cynthia Cooper1,99835HOU31.10.38210.7Cynthia Cooper1,99734HOU32.20.38510.6Sheryl Swoopes2,00029HOU32.00.36110.5Lauren Jackson2,00726SEA35.00.37310.4Nneka Ogwumike2,01625LAS31.30.37010.3Sylvia Fowles2,01731MIN30.80.35010.0Elena Delle Donne2,01929WAS31.80.3439.9Elena Delle Donne2,01525CHI32.80.3469.4Lauren Jackson2,00322SEA32.10.3339.2Cynthia Cooper1,99936HOU29.50.3359.2Yolanda Griffith1,99929SAC31.90.3309.1Lauren Jackson2,01029SEA27.90.3338.8Tamika Catchings2,00727IND29.40.3258.6Nneka Ogwumike2,01726LAS28.10.3218.5\n\n\nThe table shows Cooper-Dyke’s early WNBA seasons are among the best ever Best single-season composite ratings — based on a mix of player efficiency rating (PER) and win shares per 40 minutes — for WNBA players who played at least 375 minutes that season, 1997-2019"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html",
    "href": "cdcdata-exercise/cdcdata-exercise.html",
    "title": "CDC Data-Exercise",
    "section": "",
    "text": "#loading packages\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(gridExtra, warn.conflicts = FALSE)"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#loading-and-checking-data",
    "href": "cdcdata-exercise/cdcdata-exercise.html#loading-and-checking-data",
    "title": "CDC Data-Exercise",
    "section": "",
    "text": "#loading packages\n\nlibrary(dplyr, warn.conflicts = FALSE)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(gridExtra, warn.conflicts = FALSE)"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#data-description",
    "href": "cdcdata-exercise/cdcdata-exercise.html#data-description",
    "title": "CDC Data-Exercise",
    "section": "Data Description",
    "text": "Data Description\nThe dataset, titled “NNDSS Table II. Tuberculosis - 2019”, is sourced from the Centers for Disease Control and Prevention (CDC) through their data portal. It contains information on tuberculosis cases reported in the United States for the year 2019. The data is structured in tabular format and includes variables such as MMWR year, MMWR quarter, tuberculosis cases reported for the current quarter, previous four quarters, cumulative counts for specific years, and associated flags.\nYou can access the dataset and find more information about it on the CDC’s data portal using the following link:https://data.cdc.gov/NNDSS/NNDSS-Table-II-Tuberculosis/5avu-ff58/about_data ## Processing data"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#data-exploration",
    "href": "cdcdata-exercise/cdcdata-exercise.html#data-exploration",
    "title": "CDC Data-Exercise",
    "section": "Data Exploration",
    "text": "Data Exploration\n\n#Importing the dataset\n\ntb_data &lt;- read_csv(\"tuberculosis.csv\")\n\nRows: 228 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Reporting area, Tuberculosis†, Current quarter, flag, Tuberculosis†...\ndbl (7): MMWR Year, MMWR Quarter, Tuberculosis†, Current quarter, Tuberculos...\nlgl (3): Tuberculosis†, Previous 4 quarters Min, flag, Tuberculosis†, Previo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View the first few rows of the dataset\nhead(tb_data)\n\n# A tibble: 6 × 15\n  `Reporting area` `MMWR Year` `MMWR Quarter` `Tuberculosis†, Current quarter`\n  &lt;chr&gt;                  &lt;dbl&gt;          &lt;dbl&gt;                            &lt;dbl&gt;\n1 NEW ENGLAND             2016              1                               40\n2 CONNECTICUT             2016              1                                4\n3 MAINE                   2016              1                                5\n4 MASSACHUSETTS           2016              1                               28\n5 NEW HAMPSHIRE           2016              1                               NA\n6 RHODE ISLAND            2016              1                                3\n# ℹ 11 more variables: `Tuberculosis†, Current quarter, flag` &lt;chr&gt;,\n#   `Tuberculosis†, Previous 4 quarters Min` &lt;dbl&gt;,\n#   `Tuberculosis†, Previous 4 quarters Min, flag` &lt;lgl&gt;,\n#   `Tuberculosis†, Previous 4 quarters Max` &lt;dbl&gt;,\n#   `Tuberculosis†, Previous 4 quarters Max, flag` &lt;lgl&gt;,\n#   `Tuberculosis†, Cum 2016` &lt;dbl&gt;, `Tuberculosis†, Cum 2016, flag` &lt;chr&gt;,\n#   `Tuberculosis†, Cum 2015` &lt;dbl&gt;, `Tuberculosis†, Cum 2015, flag` &lt;chr&gt;, …\n\n#Looking at column names\ncolnames(tb_data)\n\n [1] \"Reporting area\"                              \n [2] \"MMWR Year\"                                   \n [3] \"MMWR Quarter\"                                \n [4] \"Tuberculosis†, Current quarter\"              \n [5] \"Tuberculosis†, Current quarter, flag\"        \n [6] \"Tuberculosis†, Previous 4 quarters Min\"      \n [7] \"Tuberculosis†, Previous 4 quarters Min, flag\"\n [8] \"Tuberculosis†, Previous 4 quarters Max\"      \n [9] \"Tuberculosis†, Previous 4 quarters Max, flag\"\n[10] \"Tuberculosis†, Cum 2016\"                     \n[11] \"Tuberculosis†, Cum 2016, flag\"               \n[12] \"Tuberculosis†, Cum 2015\"                     \n[13] \"Tuberculosis†, Cum 2015, flag\"               \n[14] \"Location 1\"                                  \n[15] \"Location 2\"                                  \n\n# Set seed for reproducibility\nset.seed(123)\n\n\n#Assessing missing values using Naniar package\n\nnaniar::gg_miss_var(tb_data)"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#describing-the-variables",
    "href": "cdcdata-exercise/cdcdata-exercise.html#describing-the-variables",
    "title": "CDC Data-Exercise",
    "section": "Describing the Variables",
    "text": "Describing the Variables\n1. MMWR Quarter: This column indicates the quarter within the MMWR year to which the data corresponds. Quarters are often divided into four segments: 1 (January to March), 2 (April to June), 3 (July to September), and 4 (October to December).\n\nTuberculosis†, Cum 2016: This variable represents the cumulative number of tuberculosis cases reported up to the year 2016.\nTuberculosis†, Cum 2015: This variable represents the cumulative number of tuberculosis cases reported up to the year 2015.\nTuberculosis†, Previous 4 quarters Min: This column likely represents the minimum number of tuberculosis cases reported in the previous four quarters.\nTuberculosis†, Previous 4 quarters Max: This column likely represents the maximum number of tuberculosis cases reported in the previous four quarters.\n\n\n# creating a new dataset from the above defined variable using subsetting and renaming the variables \n\n# Subset and rename variables\nnewtb_data &lt;- tb_data %&gt;%\n  subset(select = c(\"MMWR Quarter\", \n                     \"Tuberculosis†, Previous 4 quarters Min\", \n                     \"Tuberculosis†, Previous 4 quarters Max\", \n                     \"Tuberculosis†, Cum 2016\", \n                     \"Tuberculosis†, Cum 2015\")) %&gt;%\n  rename(\n    \"mmwr_quarter\" = \"MMWR Quarter\",\n    \"tb_prev_4_q_min\" = \"Tuberculosis†, Previous 4 quarters Min\",\n    \"tb_prev_4_q_max\" = \"Tuberculosis†, Previous 4 quarters Max\",\n    \"tbcases_2016\" = \"Tuberculosis†, Cum 2016\",\n    \"tbcases_2015\" = \"Tuberculosis†, Cum 2015\"\n  )\n\n\n# Display the first few rows of the new data frame (newtb_data)\nhead(newtb_data)\n\n# A tibble: 6 × 5\n  mmwr_quarter tb_prev_4_q_min tb_prev_4_q_max tbcases_2016 tbcases_2015\n         &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1            1              40              90           40           41\n2            1               4              24            4            9\n3            1               3               7            5            1\n4            1              28              56           28           26\n5            1               0               4           NA            2\n6            1               3              13            3            1\n\n#Looking at column names\ncolnames(tb_data)\n\n [1] \"Reporting area\"                              \n [2] \"MMWR Year\"                                   \n [3] \"MMWR Quarter\"                                \n [4] \"Tuberculosis†, Current quarter\"              \n [5] \"Tuberculosis†, Current quarter, flag\"        \n [6] \"Tuberculosis†, Previous 4 quarters Min\"      \n [7] \"Tuberculosis†, Previous 4 quarters Min, flag\"\n [8] \"Tuberculosis†, Previous 4 quarters Max\"      \n [9] \"Tuberculosis†, Previous 4 quarters Max, flag\"\n[10] \"Tuberculosis†, Cum 2016\"                     \n[11] \"Tuberculosis†, Cum 2016, flag\"               \n[12] \"Tuberculosis†, Cum 2015\"                     \n[13] \"Tuberculosis†, Cum 2015, flag\"               \n[14] \"Location 1\"                                  \n[15] \"Location 2\"                                  \n\n\n##Now looking at the missings in the newdata\n\n# Visualize missing values for each variable using gg_miss_var from naniar package\nnaniar::gg_miss_var(newtb_data)\n\n\n\n\n\n\n\n\n\n# Looking at the structure of the newtb_data \nstr(newtb_data)\n\ntibble [228 × 5] (S3: tbl_df/tbl/data.frame)\n $ mmwr_quarter   : num [1:228] 1 1 1 1 1 1 1 1 1 1 ...\n $ tb_prev_4_q_min: num [1:228] 40 4 3 28 0 3 0 38 31 25 ...\n $ tb_prev_4_q_max: num [1:228] 90 24 7 56 4 13 2 118 63 61 ...\n $ tbcases_2016   : num [1:228] 40 4 5 28 NA 3 NA 38 31 25 ...\n $ tbcases_2015   : num [1:228] 41 9 1 26 2 1 2 20 23 26 ...\n\n\n\n# Convert mmwr_quarter to factor\nnewtb_data$mmwr_quarter &lt;- as.factor(newtb_data$mmwr_quarter)\nstr(newtb_data)\n\ntibble [228 × 5] (S3: tbl_df/tbl/data.frame)\n $ mmwr_quarter   : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 1 1 1 1 1 1 1 1 1 1 ...\n $ tb_prev_4_q_min: num [1:228] 40 4 3 28 0 3 0 38 31 25 ...\n $ tb_prev_4_q_max: num [1:228] 90 24 7 56 4 13 2 118 63 61 ...\n $ tbcases_2016   : num [1:228] 40 4 5 28 NA 3 NA 38 31 25 ...\n $ tbcases_2015   : num [1:228] 41 9 1 26 2 1 2 20 23 26 ..."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#visualization",
    "href": "cdcdata-exercise/cdcdata-exercise.html#visualization",
    "title": "CDC Data-Exercise",
    "section": "Visualization",
    "text": "Visualization\n\n# Load necessary libraries\nlibrary(ggplot2)  # for creating plots\n\n\n# Create histograms for each variable\nhistograms &lt;- list(\n  # Histogram for Tuberculosis Previous 4 Quarters Min\n  ggplot(newtb_data, aes(x = tb_prev_4_q_min)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Previous 4 Quarters Min\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Previous 4 Quarters Min\"),\n  \n  # Histogram for Tuberculosis Previous 4 Quarters Max\n  ggplot(newtb_data, aes(x = tb_prev_4_q_max)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Previous 4 Quarters Max\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Previous 4 Quarters Max\"),\n  \n  # Histogram for Tuberculosis Cases 2016\n  ggplot(newtb_data, aes(x = tbcases_2016)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Cases 2016\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Cases 2016\"),\n  \n  # Histogram for Tuberculosis Cases 2015\n  ggplot(newtb_data, aes(x = tbcases_2015)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Cases 2015\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Cases 2015\")\n)\n\n# Display histograms side by side\ngrid.arrange(grobs = histograms, ncol = 2)\n\nWarning: Removed 22 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 7 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n# Create a box plot of Tuberculosis Previous 4 Quarters Min by MMWR Quarter\nggplot(newtb_data, aes(x = factor(mmwr_quarter), y = tb_prev_4_q_min, fill = factor(mmwr_quarter))) +\n  \n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 0.8)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Previous 4 Quarters Min\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Previous 4 Quarters Min\",\n       title = \"Box Plot of Tuberculosis Previous 4 Quarters Min by MMWR Quarter\")\n\n\n\n\n\n\n\n\n\n  # Create a box plot of Tuberculosis Previous 4 Quarters Max by MMWR Quarter\nggplot(newtb_data, aes(x = factor(mmwr_quarter), y = tb_prev_4_q_max, fill = factor(mmwr_quarter))) +\n\n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 10)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Previous 4 Quarters Max\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Previous 4 Quarters Max\",\n       title = \"Box Plot of Tuberculosis Previous 4 Quarters Max by MMWR Quarter\")\n\n\n\n\n\n\n\n\n\n  # Create a box plot of Tuberculosis Cases 2016 by MMWR Quarter\nggplot(newtb_data, aes(x = factor(mmwr_quarter), y = tbcases_2016, fill = factor(mmwr_quarter))) +\n\n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 10)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Cases 2016\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Cases 2016\",\n       title = \"Box Plot of Tuberculosis Cases 2016 by MMWR Quarter\")\n\nWarning: Removed 22 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n# Create a box plot of Tuberculosis Cases 2015 by MMWR Quarter\nggplot(newtb_data, aes(x = factor(mmwr_quarter), y = tbcases_2015, fill = factor(mmwr_quarter))) +\n\n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 10)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Cases 2015\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Cases 2015\",\n       title = \"Box Plot of Tuberculosis Cases 2015 by MMWR Quarter\")\n\nWarning: Removed 7 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#data-summary",
    "href": "cdcdata-exercise/cdcdata-exercise.html#data-summary",
    "title": "CDC Data-Exercise",
    "section": "Data Summary",
    "text": "Data Summary\n\nsummary(newtb_data)\n\n mmwr_quarter tb_prev_4_q_min  tb_prev_4_q_max   tbcases_2016   \n 1:58         Min.   :  0.00   Min.   :  0.00   Min.   :  1.00  \n 2:62         1st Qu.:  1.00   1st Qu.: 10.00   1st Qu.: 12.00  \n 3:57         Median :  8.00   Median : 24.00   Median : 33.00  \n 4:51         Mean   : 18.15   Mean   : 44.82   Mean   : 67.33  \n              3rd Qu.: 25.00   3rd Qu.: 57.00   3rd Qu.: 79.00  \n              Max.   :322.00   Max.   :610.00   Max.   :735.00  \n                                                NA's   :22      \n  tbcases_2015    \n Min.   :   1.00  \n 1st Qu.:  12.00  \n Median :  36.00  \n Mean   :  80.31  \n 3rd Qu.:  90.00  \n Max.   :1331.00  \n NA's   :7"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#this-section-is-contributed-by-ranni-tewfik.",
    "href": "cdcdata-exercise/cdcdata-exercise.html#this-section-is-contributed-by-ranni-tewfik.",
    "title": "CDC Data-Exercise",
    "section": "This section is contributed by Ranni Tewfik.",
    "text": "This section is contributed by Ranni Tewfik."
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#part-1---generating-the-synthetic-dataset",
    "href": "cdcdata-exercise/cdcdata-exercise.html#part-1---generating-the-synthetic-dataset",
    "title": "CDC Data-Exercise",
    "section": "Part 1 - Generating the Synthetic Dataset",
    "text": "Part 1 - Generating the Synthetic Dataset\n\n#Explore the five variables in the original processed data\ntable(newtb_data$mmwr_quarter)\n\n\n 1  2  3  4 \n58 62 57 51 \n\nsummary(newtb_data$tb_prev_4_q_min)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    1.00    8.00   18.15   25.00  322.00 \n\nsummary(newtb_data$tb_prev_4_q_max)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   10.00   24.00   44.82   57.00  610.00 \n\nsummary(newtb_data$tbcases_2016)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00   12.00   33.00   67.33   79.00  735.00      22 \n\nsummary(newtb_data$tbcases_2015)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   1.00   12.00   36.00   80.31   90.00 1331.00       7 \n\n#Load required R package\nlibrary(dplyr)\n\n#Set seed for reproducibility\nset.seed(123)\n\n#Define number of individuals for each mmwr_quarter level\nmmwr_quarter_levels &lt;- c(rep(1, 58), rep(2, 62), rep(3, 57), rep(4, 51))\n\n#Generate mmwr_quarter variable\nmmwr_quarter &lt;- factor(sample(mmwr_quarter_levels))\n\n#Generate other variables based on specified distributions\ntb_prev_4_q_min &lt;- round(rnorm(228, mean = 18.15, sd = 10))\ntb_prev_4_q_min &lt;- pmax(tb_prev_4_q_min, 0)\n\ntb_prev_4_q_max &lt;- round(rnorm(228, mean = 44.82, sd = 20))\ntb_prev_4_q_max &lt;- pmax(tb_prev_4_q_max, 0)\n\ntb_cases_2016 &lt;- round(rnorm(228, mean = 67.33, sd = 50))\ntb_cases_2016 &lt;- pmax(tb_cases_2016, 1)\ntb_cases_2016[sample(1:228, 22)] &lt;- NA\n\ntb_cases_2015 &lt;- round(rnorm(228, mean = 80.31, sd = 60))\ntb_cases_2015 &lt;- pmax(tb_cases_2015, 1)\ntb_cases_2015[sample(1:228, 7)] &lt;- NA\n\n#Create the synthetic dataset\nnewtb_data_rt &lt;- data.frame(\n  mmwr_quarter = mmwr_quarter,\n  tb_prev_4_q_min = tb_prev_4_q_min,\n  tb_prev_4_q_max = tb_prev_4_q_max,\n  tb_cases_2016 = tb_cases_2016,\n  tb_cases_2015 = tb_cases_2015)\n\n#Get an overview and summary of the data\nstr(newtb_data_rt)\n\n'data.frame':   228 obs. of  5 variables:\n $ mmwr_quarter   : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 3 4 4 1 4 3 1 2 1 4 ...\n $ tb_prev_4_q_min: num  14 29 8 6 51 14 21 25 13 23 ...\n $ tb_prev_4_q_max: num  22 36 52 32 2 63 28 33 75 29 ...\n $ tb_cases_2016  : num  1 45 34 6 145 1 83 110 76 24 ...\n $ tb_cases_2015  : num  149 177 82 7 62 51 127 104 29 72 ...\n\nsummary(newtb_data_rt)\n\n mmwr_quarter tb_prev_4_q_min tb_prev_4_q_max tb_cases_2016    tb_cases_2015   \n 1:58         Min.   : 0.00   Min.   : 0.00   Min.   :  1.00   Min.   :  1.00  \n 2:62         1st Qu.:12.00   1st Qu.:32.75   1st Qu.: 31.00   1st Qu.: 38.00  \n 3:57         Median :18.00   Median :44.50   Median : 68.00   Median : 79.00  \n 4:51         Mean   :18.79   Mean   :44.89   Mean   : 68.55   Mean   : 82.16  \n              3rd Qu.:25.00   3rd Qu.:58.25   3rd Qu.: 99.00   3rd Qu.:123.00  \n              Max.   :51.00   Max.   :93.00   Max.   :202.00   Max.   :242.00  \n                                              NA's   :22       NA's   :7       \n\n\nFirst, I explored the original processed dataset “newtb_data” to better understand the variables and their distributions. I used ChatGPT to help me produce the synthetic dataset “newtb_data_rt” with the same structure as “newtb_data”.\nChatGPT prompt:\n“Write R code that generates a dataset of 228 individuals with five variables: mmwr_quarter, tb_prev_4_q_min, tb_prev_4_q_max, tbcases_2016, and tbcases_2015. The variable mmwr_quarter is a factor variable and has four levels: level 1 with 58 individuals, level 2 with 62 individuals, level 3 with 57 individuals, and level 4 with 51 individuals. The variable tb_prev_4_q_min is numerical with whole integers ranging from 0 to 322, median is 8, and mean is 18.15. The variable tb_prev_4_q_max is numerical with whole integers ranging from 0 to 610, median is 24, and mean is 44.82. The variable tb_cases_2016 is numerical with whole integers ranging from 1 to 735, median is 33, mean is 67.33, and 22 individuals with missing value. The variable tb_cases_2015 is numerical with whole integers ranging from 1 to 1331, median is 36, mean is 80.31, and 7 individuals with missing value. Add thorough documentation to the R code.”"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html#part-2---exploring-the-synthetic-dataset",
    "href": "cdcdata-exercise/cdcdata-exercise.html#part-2---exploring-the-synthetic-dataset",
    "title": "CDC Data-Exercise",
    "section": "Part 2 - Exploring the Synthetic Dataset",
    "text": "Part 2 - Exploring the Synthetic Dataset\n\n# Create histograms for each variable\nhistograms &lt;- list(\n  # Histogram for Tuberculosis Previous 4 Quarters Min\n  ggplot(newtb_data_rt, aes(x = tb_prev_4_q_min)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Previous 4 Quarters Min\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Previous 4 Quarters Min\"),\n  \n  # Histogram for Tuberculosis Previous 4 Quarters Max\n  ggplot(newtb_data_rt, aes(x = tb_prev_4_q_max)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Previous 4 Quarters Max\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Previous 4 Quarters Max\"),\n  \n  # Histogram for Tuberculosis Cases 2016\n  ggplot(newtb_data_rt, aes(x = tb_cases_2016)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Cases 2016\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Cases 2016\"),\n  \n  # Histogram for Tuberculosis Cases 2015\n  ggplot(newtb_data_rt, aes(x = tb_cases_2015)) +\n    geom_histogram(fill = \"blue\", color = \"black\", bins = 20) +\n    labs(x = \"Tuberculosis Cases 2015\", y = \"Frequency\", \n         title = \"Histogram of Tuberculosis Cases 2015\")\n)\n\n# Display histograms side by side\ngrid.arrange(grobs = histograms, ncol = 2)\n\nWarning: Removed 22 rows containing non-finite values (`stat_bin()`).\n\n\nWarning: Removed 7 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nThe histograms for the variables “tb_prev_4_q_min” and “tb_prev_4_q_max” show an approximately normal distribution, but the histograms for the variables “tb_cases_2016” and “tb_cases_2015” do not show an approximately normal distribution. The histograms in the new synthetic dataset look slightly similar to the histograms in the original processed dataset for the variables “tb_cases_2016” and “tb_cases_2015” but not for the variables “tb_prev_4_q_min” and “tb_prev_4_q_max”.\n\n# Create a box plot of Tuberculosis Previous 4 Quarters Min by MMWR Quarter\nggplot(newtb_data_rt, aes(x = factor(mmwr_quarter), y = tb_prev_4_q_min, fill = factor(mmwr_quarter))) +\n  \n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 0.8)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Previous 4 Quarters Min\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Previous 4 Quarters Min\",\n       title = \"Box Plot of Tuberculosis Previous 4 Quarters Min by MMWR Quarter\")\n\n\n\n\n\n\n\n\nThe box plots for tuberculosis for the previous four MMWR quarters (min) show an approximately normal distribution, however, MMWR Quarters 3 and 4 are slightly positively skewed. The box plots in the original processed dataset have more positive skew and more outliers compared with the box plots in the new synthetic data set.\n\n  # Create a box plot of Tuberculosis Previous 4 Quarters Max by MMWR Quarter\nggplot(newtb_data_rt, aes(x = factor(mmwr_quarter), y = tb_prev_4_q_max, fill = factor(mmwr_quarter))) +\n\n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 10)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Previous 4 Quarters Max\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Previous 4 Quarters Max\",\n       title = \"Box Plot of Tuberculosis Previous 4 Quarters Max by MMWR Quarter\")\n\n\n\n\n\n\n\n\nThe box plots for tuberculosis for the previous four MMWR quarters (max) show an approximately normal distribution. The box plots in the original processed dataset have more positive skew and more outliers compared with the box plots in the new synthetic data set.\n\n  # Create a box plot of Tuberculosis Cases 2016 by MMWR Quarter\nggplot(newtb_data_rt, aes(x = factor(mmwr_quarter), y = tb_cases_2016, fill = factor(mmwr_quarter))) +\n\n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 10)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Cases 2016\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Cases 2016\",\n       title = \"Box Plot of Tuberculosis Cases 2016 by MMWR Quarter\")\n\nWarning: Removed 22 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nThe box plots for tuberculosis cases in 2016 for different MMWR quarters are positively skewed with some outliers. The box plots in the new synthetic dataset are somewhat similar to the box plots in the original processed dataset.\n\n# Create a box plot of Tuberculosis Cases 2015 by MMWR Quarter\nggplot(newtb_data_rt, aes(x = factor(mmwr_quarter), y = tb_cases_2015, fill = factor(mmwr_quarter))) +\n\n  # Add a box plot layer with dodged position\n  geom_boxplot(position = position_dodge(width = 10)) +\n  \n  # Label the x-axis as \"MMWR Quarter\" and y-axis as \"Tuberculosis Cases 2015\"\n  labs(x = \"MMWR Quarter\", y = \"Tuberculosis Cases 2015\",\n       title = \"Box Plot of Tuberculosis Cases 2015 by MMWR Quarter\")\n\nWarning: Removed 7 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nThe box plots for tuberculosis cases in 2015 for different MMWR quarters show an approximate normal distribution. The box plots in the new synthetic dataset are not similar to the box plots in the original processed dataset."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About Me",
    "section": "",
    "text": "One evening during my Christmas break\n\n\nI am a first-year Ph.D. student, specializing in Epidemiology at the Global Health Institute. My background includes expertise in computer hardware, open-source systems, network design and deployments, Docker containerization, Linux, and Health Informatics.\n\n\nI hold a Bachelor of Science in Computer Science and a Master’s in Health Informatics. My research interests revolve around data science, AI, and the intersection of technology and health. I am currently working with Dr. Christopher Whalen and Dr. Juliet Sekandi at the Global Health Institute, focusing on TB research in Africa, specifically in Uganda.\nI am actively involved in projects that leverage mobile digital technologies to enhance data collection, monitoring, and adherence in TB. Additionally, I explore the use of smartwatches in collecting mobility data for participants at risk of Latent Tuberculosis Infection (LTBI).\n\n\n\nWhile my data analysis skills are currently at a beginner’s level, I have acquired knowledge in R through EPID8500 and SAS. I am motivated to enhance my analysis skills further.\n\n\n\nIn the Modern Applied Data Analysis (MADA) course, I aim to improve my R programming skills and enhance my data analysis capabilities using modern tools. I expect to gain skills that will propel me toward a successful career in data science and AI.\nWatch a useful video on Quarto:"
  },
  {
    "objectID": "aboutme.html#background-and-research-interests",
    "href": "aboutme.html#background-and-research-interests",
    "title": "About Me",
    "section": "",
    "text": "I hold a Bachelor of Science in Computer Science and a Master’s in Health Informatics. My research interests revolve around data science, AI, and the intersection of technology and health. I am currently working with Dr. Christopher Whalen and Dr. Juliet Sekandi at the Global Health Institute, focusing on TB research in Africa, specifically in Uganda.\nI am actively involved in projects that leverage mobile digital technologies to enhance data collection, monitoring, and adherence in TB. Additionally, I explore the use of smartwatches in collecting mobility data for participants at risk of Latent Tuberculosis Infection (LTBI)."
  },
  {
    "objectID": "aboutme.html#data-analysis-experience",
    "href": "aboutme.html#data-analysis-experience",
    "title": "About Me",
    "section": "",
    "text": "While my data analysis skills are currently at a beginner’s level, I have acquired knowledge in R through EPID8500 and SAS. I am motivated to enhance my analysis skills further."
  },
  {
    "objectID": "aboutme.html#mada-course-expectations",
    "href": "aboutme.html#mada-course-expectations",
    "title": "About Me",
    "section": "",
    "text": "In the Modern Applied Data Analysis (MADA) course, I aim to improve my R programming skills and enhance my data analysis capabilities using modern tools. I expect to gain skills that will propel me toward a successful career in data science and AI.\nWatch a useful video on Quarto:"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "#loading packages\nlibrary(dslabs)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nhead(gapminder)\n\n              country year infant_mortality life_expectancy fertility\n1             Albania 1960           115.40           62.87      6.19\n2             Algeria 1960           148.20           47.50      7.65\n3              Angola 1960           208.00           35.98      7.32\n4 Antigua and Barbuda 1960               NA           62.97      4.43\n5           Argentina 1960            59.87           65.39      3.11\n6             Armenia 1960               NA           66.86      4.55\n  population          gdp continent          region\n1    1636054           NA    Europe Southern Europe\n2   11124892  13828152297    Africa Northern Africa\n3    5270844           NA    Africa   Middle Africa\n4      54681           NA  Americas       Caribbean\n5   20619075 108322326649  Americas   South America\n6    1867396           NA      Asia    Western Asia"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#loading-and-checking-data",
    "href": "coding-exercise/coding-exercise.html#loading-and-checking-data",
    "title": "R Coding Exercise",
    "section": "",
    "text": "#loading packages\nlibrary(dslabs)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nhead(gapminder)\n\n              country year infant_mortality life_expectancy fertility\n1             Albania 1960           115.40           62.87      6.19\n2             Algeria 1960           148.20           47.50      7.65\n3              Angola 1960           208.00           35.98      7.32\n4 Antigua and Barbuda 1960               NA           62.97      4.43\n5           Argentina 1960            59.87           65.39      3.11\n6             Armenia 1960               NA           66.86      4.55\n  population          gdp continent          region\n1    1636054           NA    Europe Southern Europe\n2   11124892  13828152297    Africa Northern Africa\n3    5270844           NA    Africa   Middle Africa\n4      54681           NA  Americas       Caribbean\n5   20619075 108322326649  Americas   South America\n6    1867396           NA      Asia    Western Asia"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#processing-data",
    "href": "coding-exercise/coding-exercise.html#processing-data",
    "title": "R Coding Exercise",
    "section": "Processing data",
    "text": "Processing data\n\n#get an overview of data structure\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n#determine the type of object gapminder is\nclass(gapminder)\n\n[1] \"data.frame\"\n\n#  Code that assigns only the African countries to a new object/variable called africadata. \n#Run str and summary on the new object you created.\n\n# Use subset to filter rows where Continent is \"Africa\"\nafricadata &lt;- subset(gapminder, continent == \"Africa\")\n\n# Display the structure of africadata\nstr(africadata)\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n# Display summary statistics of africadata\nsummary(africadata)\n\n         country          year      infant_mortality life_expectancy\n Algeria     :  57   Min.   :1960   Min.   : 11.40   Min.   :13.20  \n Angola      :  57   1st Qu.:1974   1st Qu.: 62.20   1st Qu.:48.23  \n Benin       :  57   Median :1988   Median : 93.40   Median :53.98  \n Botswana    :  57   Mean   :1988   Mean   : 95.12   Mean   :54.38  \n Burkina Faso:  57   3rd Qu.:2002   3rd Qu.:124.70   3rd Qu.:60.10  \n Burundi     :  57   Max.   :2016   Max.   :237.40   Max.   :77.60  \n (Other)     :2565                  NA's   :226                     \n   fertility       population             gdp               continent   \n Min.   :1.500   Min.   :    41538   Min.   :4.659e+07   Africa  :2907  \n 1st Qu.:5.160   1st Qu.:  1605232   1st Qu.:8.373e+08   Americas:   0  \n Median :6.160   Median :  5570982   Median :2.448e+09   Asia    :   0  \n Mean   :5.851   Mean   : 12235961   Mean   :9.346e+09   Europe  :   0  \n 3rd Qu.:6.860   3rd Qu.: 13888152   3rd Qu.:6.552e+09   Oceania :   0  \n Max.   :8.450   Max.   :182201962   Max.   :1.935e+11                  \n NA's   :51      NA's   :51          NA's   :637                        \n                       region   \n Eastern Africa           :912  \n Western Africa           :912  \n Middle Africa            :456  \n Northern Africa          :342  \n Southern Africa          :285  \n Australia and New Zealand:  0  \n (Other)                  :  0  \n\n\n\n#Take the africadata object and create two new objects (name them whatever you want),\n#one that contains only infant_mortality and life_expectancy and one that contains \n#only population and life_expectancy.\n\n# Assuming africadata has columns like \"infant_mortality,\" \"life_expectancy,\" and \"population\"\n# Replace column names as per your actual data frame structure\n\n\n# Create object with only \"infant_mortality\" and \"life_expectancy\"\nsubset1 &lt;- select(africadata, infant_mortality, life_expectancy)\n\n# Create object with only \"population\" and \"life_expectancy\"\nsubset2 &lt;- select(africadata, population, life_expectancy)\n\n# Display the structure of subset1 and subset1\nstr(subset1)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\nstr(subset2)\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\n# Display summary statistics of subset1\nsummary(subset1)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\nsummary(subset2)\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#plotting",
    "href": "coding-exercise/coding-exercise.html#plotting",
    "title": "R Coding Exercise",
    "section": "Plotting",
    "text": "Plotting\n\n#Using the new variables you created, plot life expectancy as a function of infant mortality and as a function of population size. \n#Make two separate plots. \n#Plot the data as points. For the plot with population size on the x-axis, set the x-axis to a log scale.\n# Plot life expectancy as a function of infant mortality\n\n# using ggplot2 package to plot \nplot1 &lt;- ggplot(subset1, aes(x = infant_mortality, y = life_expectancy)) +\n  geom_point() +\n  labs(title = \"Life Expectancy vs. Infant Mortality\",\n       x = \"Infant Mortality\",\n       y = \"Life Expectancy\")\nplot1\n\nWarning: Removed 226 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n# Plot life expectancy as a function of population size (log scale on x-axis)\nplot2 &lt;- ggplot(subset2, aes(x = log10(population), y = life_expectancy)) +\n  geom_point() +\n  labs(title = \"Life Expectancy vs. Population Size\",\n       x = \"Log Population Size\",\n       y = \"Life Expectancy\")\nplot2\n\nWarning: Removed 51 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#more-data-processing",
    "href": "coding-exercise/coding-exercise.html#more-data-processing",
    "title": "R Coding Exercise",
    "section": "More data processing",
    "text": "More data processing\n\n# Identify years with missing data for infant mortality\nyears_with_missing_data &lt;- unique(africadata$year[is.na(africadata$infant_mortality)])\nyears_with_missing_data\n\n [1] 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974\n[16] 1975 1976 1977 1978 1979 1980 1981 2016\n\n# Choose the year 2000 and create a new object\nafricadata_2000 &lt;- africadata[africadata$year == 2000, ]\n\n# Display the structure of africadata_2000\nstr(africadata_2000)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n# Display summary statistics of africadata_2000\nsummary(africadata_2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#more-plotting",
    "href": "coding-exercise/coding-exercise.html#more-plotting",
    "title": "R Coding Exercise",
    "section": "More plotting",
    "text": "More plotting\n\n# Plot life expectancy as a function of infant mortality for the year 2000\nplot_infant_mortality &lt;- ggplot(africadata_2000, aes(x = infant_mortality, y = life_expectancy)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +  # Add a fitted line\n  labs(title = \"Life Expectancy vs. Infant Mortality (Year 2000)\",\n       x = \"Infant Mortality\",\n       y = \"Life Expectancy\") +\n  theme_hc()\nplot_infant_mortality\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n# Fit linear regression model for life expectancy vs. infant mortality\nmodel_infant_mortality &lt;- lm(life_expectancy ~ infant_mortality, data = africadata_2000)\nsummary(model_infant_mortality)\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = africadata_2000)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      71.29331    2.42611  29.386  &lt; 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\n\nThe linear regression model suggests a statistically significant negative relationship between infant mortality and life expectancy for the year 2000. As infant mortality increases, life expectancy is expected to decrease. The model explains a significant portion of the variability in life expectancy based on infant mortality.\n\n# Plot life expectancy as a function of population size (log scale on x-axis) for the year 2000\nplot_population_size &lt;- ggplot(africadata_2000, aes(x = log10(population), y = life_expectancy)) +\n  geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +  # Add a fitted line\n  labs(title = \"Life Expectancy vs. Population Size (Year 2000)\",\n       x = \"Log Population Size\",\n       y = \"Life Expectancy\") +\ntheme_hc()\nplot_population_size\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#simple-model-fits",
    "href": "coding-exercise/coding-exercise.html#simple-model-fits",
    "title": "R Coding Exercise",
    "section": "Simple model fits",
    "text": "Simple model fits\n\n# Fit linear regression model for life expectancy vs. log population size\nmodel_population_size &lt;- lm(life_expectancy ~ log10(population), data = africadata_2000)\nsummary(model_population_size)\n\n\nCall:\nlm(formula = life_expectancy ~ log10(population), data = africadata_2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.113  -4.809  -1.554   3.907  18.863 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         65.324     12.520   5.217 3.65e-06 ***\nlog10(population)   -1.315      1.829  -0.719    0.476    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.502 on 49 degrees of freedom\nMultiple R-squared:  0.01044,   Adjusted R-squared:  -0.009755 \nF-statistic: 0.517 on 1 and 49 DF,  p-value: 0.4755\n\n\nThe linear regression model suggests that, for the year 2000, there is not enough evidence to conclude a significant relationship between log-transformed population size and life expectancy. The coefficient for log-transformed population size is not statistically significant, and the model explains only a very small percentage of the variability in life expectancy.\n\n# Fit linear regression model with life expectancy as the outcome and infant mortality as the predictor\nfit_infant_mortality &lt;- lm(life_expectancy ~ infant_mortality, data = africadata_2000)\nsummary(fit_infant_mortality)\n\n\nCall:\nlm(formula = life_expectancy ~ infant_mortality, data = africadata_2000)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.6651  -3.7087   0.9914   4.0408   8.6817 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      71.29331    2.42611  29.386  &lt; 2e-16 ***\ninfant_mortality -0.18916    0.02869  -6.594 2.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.221 on 49 degrees of freedom\nMultiple R-squared:  0.4701,    Adjusted R-squared:  0.4593 \nF-statistic: 43.48 on 1 and 49 DF,  p-value: 2.826e-08\n\n\nThe linear regression model for the year 2000 suggests a statistically significant negative relationship between infant mortality and life expectancy. As infant mortality increases, life expectancy is expected to decrease. The model explains a significant portion of the variability in life expectancy based on infant mortality.\n\n# Fit linear regression model with life expectancy as the outcome and population size as the predictor\nfit_population_size &lt;- lm(life_expectancy ~ log10(population), data = africadata_2000)\nsummary(fit_population_size)\n\n\nCall:\nlm(formula = life_expectancy ~ log10(population), data = africadata_2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.113  -4.809  -1.554   3.907  18.863 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         65.324     12.520   5.217 3.65e-06 ***\nlog10(population)   -1.315      1.829  -0.719    0.476    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.502 on 49 degrees of freedom\nMultiple R-squared:  0.01044,   Adjusted R-squared:  -0.009755 \nF-statistic: 0.517 on 1 and 49 DF,  p-value: 0.4755\n\n\nThe linear regression model for the year 2000 suggests that there is not enough evidence to conclude a significant relationship between log-transformed population size and life expectancy. The coefficient for log-transformed population size is not statistically significant, and the model explains only a very small percentage of the variability in life expectancy."
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#more-data-exploration-stars",
    "href": "coding-exercise/coding-exercise.html#more-data-exploration-stars",
    "title": "R Coding Exercise",
    "section": "More data exploration (stars)",
    "text": "More data exploration (stars)\nChoose dataset stars from the dslabs package. Details of variables in stars are listed below. 1. star: Name of star. 2. magnitude: Absolute magnitude of the star, which is a function of the star’s luminosity and distance to the star. 3. temp: Surface temperature in degrees Kelvin (K). 4. type: Spectral class of star in the OBAFGKM system.\n\n#Load package dslabs and tidyverse\nlibrary(\"dslabs\")\nlibrary(\"tidyverse\")\n#a preview of stars\nhead(stars)\n\n            star magnitude temp type\n1            Sun       4.8 5840    G\n2        SiriusA       1.4 9620    A\n3        Canopus      -3.1 7400    F\n4       Arcturus      -0.4 4590    K\n5 AlphaCentauriA       4.3 5840    G\n6           Vega       0.5 9900    A\n\n#check structure of stars\nstr(stars) \n\n'data.frame':   96 obs. of  4 variables:\n $ star     : Factor w/ 95 levels \"*40EridaniA\",..: 87 85 48 38 33 92 49 79 77 47 ...\n $ magnitude: num  4.8 1.4 -3.1 -0.4 4.3 0.5 -0.6 -7.2 2.6 -5.7 ...\n $ temp     : int  5840 9620 7400 4590 5840 9900 5150 12140 6580 3200 ...\n $ type     : chr  \"G\" \"A\" \"F\" \"K\" ...\n\n#check summary of stars\nsummary(stars)\n\n          star      magnitude           temp           type          \n Altair     : 2   Min.   :-8.000   Min.   : 2500   Length:96         \n *40EridaniA: 1   1st Qu.:-1.800   1st Qu.: 3168   Class :character  \n *40EridaniB: 1   Median : 2.400   Median : 5050   Mode  :character  \n *40EridaniC: 1   Mean   : 4.257   Mean   : 8752                     \n *61CygniA  : 1   3rd Qu.:11.325   3rd Qu.: 9900                     \n *61CygniB  : 1   Max.   :17.000   Max.   :33600                     \n (Other)    :89"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#processing-data-stars",
    "href": "coding-exercise/coding-exercise.html#processing-data-stars",
    "title": "R Coding Exercise",
    "section": "Processing data (stars)",
    "text": "Processing data (stars)\nCreate star_ABKM which contains stars in the spectral classes of A/B/K/M \n(these classes have more than 10 stars).\n\n#check frequencies for the spectral class of stars\ntable(stars$type)\n\n\n A  B DA DB DF  F  G  K  M  O \n13 19  2  1  1  7  4 16 32  1 \n\n#Create dataset star_ABKM that contains stars from spectral classes of A/B/K/M, as only these classes have more than 10 stars, and change type into a factor variable\nstar_ABKM  &lt;- \n  stars %&gt;% \n    filter(type %in% c(\"A\",\"B\",\"K\",\"M\")) %&gt;%\n      mutate(type=factor(type) )\n#Check structure and summary of star_ABKM\nstr(star_ABKM) \n\n'data.frame':   80 obs. of  4 variables:\n $ star     : Factor w/ 95 levels \"*40EridaniA\",..: 85 38 92 79 47 22 62 36 26 86 ...\n $ magnitude: num  1.4 -0.4 0.5 -7.2 -5.7 -2.4 -5.3 2.2 -0.8 -3.4 ...\n $ temp     : int  9620 4590 9900 12140 3200 20500 25500 8060 4130 25500 ...\n $ type     : Factor w/ 4 levels \"A\",\"B\",\"K\",\"M\": 1 3 1 2 4 2 2 1 3 2 ...\n\nsummary(star_ABKM)\n\n           star      magnitude           temp       type  \n Altair      : 2   Min.   :-7.200   Min.   : 2500   A:13  \n *40EridaniA : 1   1st Qu.:-1.225   1st Qu.: 2940   B:19  \n *40EridaniC : 1   Median : 2.200   Median : 4590   K:16  \n *61CygniA   : 1   Mean   : 4.645   Mean   : 8616   M:32  \n *61CygniB   : 1   3rd Qu.:11.900   3rd Qu.: 9900         \n *70OphiuchiA: 1   Max.   :17.000   Max.   :28000         \n (Other)     :73"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#plotting-stars",
    "href": "coding-exercise/coding-exercise.html#plotting-stars",
    "title": "R Coding Exercise",
    "section": "Plotting (stars)",
    "text": "Plotting (stars)\nPlot absolute magnitude of a star as a function of log(surface temperature) and as a function of spectral class.\n\n#Scatterplot: magnitude ~ log(temp)  \nggplot(star_ABKM, aes(log(temp), magnitude)) + \n  geom_point()\n\n\n\n\n\n\n\n#Boxplot: magnitude ~ type  \nggplot(star_ABKM, aes(type, magnitude)) + \n  geom_boxplot()"
  },
  {
    "objectID": "coding-exercise/coding-exercise.html#fit-2-simple-linear-modelsstars",
    "href": "coding-exercise/coding-exercise.html#fit-2-simple-linear-modelsstars",
    "title": "R Coding Exercise",
    "section": "Fit 2 simple linear models(stars)",
    "text": "Fit 2 simple linear models(stars)\nFit simple linear models with lm() function in R. Model 1: absolute magnitude \nas the outcome, and log(surface temperature) as the predictor; Model 2: \nabsolute magnitude as the outcome, and spectral class as the predictor. \nFindings: Among stars of A/B/K/M spectral classes, 1 additional unit in the \nlog(surface temperature) was significantly associated with a decrease of 7.6 \nin the absolute magnitude (P-value&lt;0.001); class K stars(P-value=0.014) and \nclass M stars (P-value&lt;0.001) had significantly higher absolute magnitude \nthan class A stars; class B stars (P-value=0.009) had significantly lower \nabsolute magnitude than class A stars.\n\n#Linear model: magnitude~log(temp)\nfit1&lt;-lm(magnitude~log(temp), data=star_ABKM)\nsummary(fit1)\n\n\nCall:\nlm(formula = magnitude ~ log(temp), data = star_ABKM)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2219  -0.5008   0.8053   2.4234   5.7984 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  71.0185     4.9384   14.38   &lt;2e-16 ***\nlog(temp)    -7.6195     0.5645  -13.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.048 on 78 degrees of freedom\nMultiple R-squared:  0.7002,    Adjusted R-squared:  0.6964 \nF-statistic: 182.2 on 1 and 78 DF,  p-value: &lt; 2.2e-16\n\n#Linear model: magnitude~type\nfit2&lt;-lm(magnitude~type, data=star_ABKM)\nsummary(fit2)\n\n\nCall:\nlm(formula = magnitude ~ type, data = star_ABKM)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-17.184  -1.009   0.727   1.935   5.516 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.3615     1.1263   0.321  0.74909    \ntypeB        -3.8931     1.4616  -2.664  0.00944 ** \ntypeK         3.7947     1.5163   2.503  0.01447 *  \ntypeM        11.1228     1.3356   8.328 2.59e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.061 on 76 degrees of freedom\nMultiple R-squared:  0.706, Adjusted R-squared:  0.6944 \nF-statistic: 60.83 on 3 and 76 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data Exercise",
    "section": "",
    "text": "Tuberculosis (TB) remains a major global health concern, with millions of new cases reported annually. This exercise reviews and analyzes key factors associated with TB, ranging from demographic and lifestyle factors to health-related variables. The aim of analysis provides understanding of factors associated to TB.The data used in this exercise is synthetic data and was created with the help of a generative Pre-trained Transformer 3.5 (ChatGPT3.5)\n# Install and load necessary packages\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Set a seed for reproducibility\nset.seed(123)\nThe set seed was used above for reproducibility reasons and randomly created n =998 observations"
  },
  {
    "objectID": "data-exercise/data-exercise.html#data-processing",
    "href": "data-exercise/data-exercise.html#data-processing",
    "title": "Data Exercise",
    "section": "Data Processing",
    "text": "Data Processing\n\n# Populate the dataframe with synthetic data\nn &lt;- 998  # Number of observations\n\n# creating and populating Variables\ntb_data &lt;- data.frame(\n  age = sample(18:65, n, replace = TRUE),  # Sample ages from 18 to 65\n  gender = sample(c(\"Male\", \"Female\"), n, replace = TRUE),  # Randomly assign gender\n  smoking_status = sample(c(\"Smoker\", \"Non-Smoker\"), n, replace = TRUE),  # Randomly assign smoking status\n  diabetes_status = sample(c(\"Diabetic\", \"Non-Diabetic\"), n, replace = TRUE),  # Randomly assign diabetes status\n  urban_rural_status = sample(c(\"Urban\", \"Rural\"), n, replace = TRUE)  # Randomly assign urban/rural status\n)\n\n# Create associations between variables and TB status\ntb_data$tb_status_prob &lt;- plogis(0.05 * (tb_data$age - 65) +\n                                   ifelse(tb_data$smoking_status == \"Smoker\", 1, 0) +\n                                   ifelse(tb_data$diabetes_status == \"Diabetic\", 1, 0) +\n                                   ifelse(tb_data$urban_rural_status == \"Urban\", 0.5, 0))  # Calculate the probability of having TB\n\n# Generate TB status based on probability\ntb_data$tb_status &lt;- ifelse(runif(n) &lt; tb_data$tb_status_prob, 1, 0)  # Assign 1 for TB case, 0 for not TB case\n\n# Summary statistics\nsummary(tb_data)\n\n      age           gender          smoking_status     diabetes_status   \n Min.   :18.00   Length:998         Length:998         Length:998        \n 1st Qu.:29.00   Class :character   Class :character   Class :character  \n Median :42.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :41.43                                                           \n 3rd Qu.:53.00                                                           \n Max.   :65.00                                                           \n urban_rural_status tb_status_prob      tb_status    \n Length:998         Min.   :0.08707   Min.   :0.000  \n Class :character   1st Qu.:0.33181   1st Qu.:0.000  \n Mode  :character   Median :0.51250   Median :0.000  \n                    Mean   :0.50969   Mean   :0.498  \n                    3rd Qu.:0.67918   3rd Qu.:1.000  \n                    Max.   :0.92414   Max.   :1.000"
  },
  {
    "objectID": "data-exercise/data-exercise.html#data-visualizations",
    "href": "data-exercise/data-exercise.html#data-visualizations",
    "title": "Data Exercise",
    "section": "Data Visualizations",
    "text": "Data Visualizations\nNow I will carry some visualizations for some the variables\n\n# Boxplot of Age by TB Status\nggplot(tb_data, aes(x = factor(tb_status), y = age, fill = factor(tb_status))) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Age by TB Status\",\n       x = \"TB Status\",\n       y = \"Age\")\n\n\n\n\n\n\n\n\nThe 0 = No TB and 1 = TB\n\n# Boxplot of Age by Smoking Status\nggplot(tb_data, aes(x = factor(tb_status), y = age, fill = tb_status)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Age by tb_status\",\n       x = \"tb_status\",\n       y = \"Age\")\n\n\n\n\n\n\n\n\n\n# Histogram of Age Stratified by TB Status\nggplot(tb_data, aes(x = age, fill = factor(tb_status))) +\n  geom_histogram(binwidth = 5, alpha = 0.7, position = \"identity\") +\n  labs(title = \"Histogram of Age Stratified by TB Status\",\n       x = \"Age\",\n       fill = \"TB Status\")\n\n\n\n\n\n\n\n\nThe 0 = No TB and 1 = TB\nNow I will compare the distribution of age across TB Status.\n\n# Violin Plot of Age by TB Status\nggplot(tb_data, aes(x = factor(tb_status), y = age, fill = factor(tb_status))) +\n  geom_violin() +\n  labs(title = \"Violin Plot of Age by TB Status\",\n       x = \"TB Status\",\n       y = \"Age\",\n       fill = \"TB Status\")\n\n\n\n\n\n\n\n\n\n# Bar Plot of Smoking Status Stratified by TB Status\nggplot(tb_data, aes(x = smoking_status, fill = factor(tb_status))) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Bar Plot of Smoking Status Stratified by TB Status\",\n       x = \"Smoking Status\",\n       fill = \"TB Status\")\n\n\n\n\n\n\n\n\nThe bar graph shows that TB is more prevalent in smokers compared to the non smokers\n\n# Creating a table stratified by TB status\n\n# List to store cross-tabulation tables for each variable\ncross_tab_list &lt;- list()\n\n# Cross-tabulation table for tb_status and gender\ncross_tab_gender &lt;- table(tb_data$tb_status, tb_data$gender)\ncross_tab_list[[\"Gender\"]] &lt;- cross_tab_gender\n\n# Cross-tabulation table for tb_status and smoking_status\ncross_tab_smoking &lt;- table(tb_data$tb_status, tb_data$smoking_status)\ncross_tab_list[[\"Smoking Status\"]] &lt;- cross_tab_smoking\n\n# Cross-tabulation table for tb_status and diabetes_status\ncross_tab_diabetes &lt;- table(tb_data$tb_status, tb_data$diabetes_status)\ncross_tab_list[[\"Diabetes Status\"]] &lt;- cross_tab_diabetes\n\n# Cross-tabulation table for tb_status and urban_rural_status\ncross_tab_urban_rural &lt;- table(tb_data$tb_status, tb_data$urban_rural_status)\ncross_tab_list[[\"Urban/Rural Status\"]] &lt;- cross_tab_urban_rural\n\n# Combine all cross-tabulation tables into one table using cbind\ncombined_cross_tab &lt;- do.call(cbind, cross_tab_list)\n\n# Print the combined table\ncat(\"Combined Cross-tabulation Table for TB Status and Other Variables:\\n\")\n\nCombined Cross-tabulation Table for TB Status and Other Variables:\n\nprint(combined_cross_tab)\n\n  Female Male Non-Smoker Smoker Diabetic Non-Diabetic Rural Urban\n0    228  273        288    213      202          299   291   210\n1    254  243        187    310      274          223   251   246\n\n\nThe above table shows the distributions of TB status across different factors"
  },
  {
    "objectID": "data-exercise/data-exercise.html#model-fitting",
    "href": "data-exercise/data-exercise.html#model-fitting",
    "title": "Data Exercise",
    "section": "Model Fitting",
    "text": "Model Fitting\nNow I will fit the different variables to look at the association using step-wise method\n\n# Fitting a logistic regression models \nmodel1 &lt;- glm(tb_status ~ age, data = tb_data, family = \"binomial\")\nsummary(model1)\n\n\nCall:\nglm(formula = tb_status ~ age, family = \"binomial\", data = tb_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.068982   0.223218  -9.269   &lt;2e-16 ***\nage          0.049734   0.005141   9.675   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1383.5  on 997  degrees of freedom\nResidual deviance: 1280.4  on 996  degrees of freedom\nAIC: 1284.4\n\nNumber of Fisher Scoring iterations: 4\n\n\nModel1 suggests that age is a statistically significant associated with Tuberculosis with P-value &lt; 0.05\n\nmodel2 &lt;- glm(tb_status ~ age + gender,\n                      data = tb_data, family = \"binomial\")\nsummary(model2)\n\n\nCall:\nglm(formula = tb_status ~ age + gender, family = \"binomial\", \n    data = tb_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.954275   0.233296  -8.377   &lt;2e-16 ***\nage          0.049675   0.005145   9.654   &lt;2e-16 ***\ngenderMale  -0.216892   0.133752  -1.622    0.105    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1383.5  on 997  degrees of freedom\nResidual deviance: 1277.7  on 995  degrees of freedom\nAIC: 1283.7\n\nNumber of Fisher Scoring iterations: 4\n\n\nModel2 suggests that gender variable may not be a statistically significant predictor of TB status in this model with p-value &gt; 0.05\n\nmodel3 &lt;- glm(tb_status ~ age + gender + smoking_status,\n                      data = tb_data, family = \"binomial\")\nsummary(model3)\n\n\nCall:\nglm(formula = tb_status ~ age + gender + smoking_status, family = \"binomial\", \n    data = tb_data)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)          -2.472177   0.256980  -9.620  &lt; 2e-16 ***\nage                   0.051108   0.005273   9.693  &lt; 2e-16 ***\ngenderMale           -0.214574   0.136601  -1.571    0.116    \nsmoking_statusSmoker  0.868348   0.137558   6.313 2.74e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1383.5  on 997  degrees of freedom\nResidual deviance: 1236.7  on 994  degrees of freedom\nAIC: 1244.7\n\nNumber of Fisher Scoring iterations: 4\n\n\nAge and smoking status are statistically significant associated with Tuberculosis status in model3. However, the gender variable does not appear again to be statistically significant, as the p-value is above the conventional significance level.\n\nmodel4 &lt;- glm(tb_status ~ age + gender + smoking_status + diabetes_status ,\n                      data = tb_data, family = \"binomial\")\nsummary(model4)\n\n\nCall:\nglm(formula = tb_status ~ age + gender + smoking_status + diabetes_status, \n    family = \"binomial\", data = tb_data)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -2.216070   0.262147  -8.454  &lt; 2e-16 ***\nage                          0.054673   0.005436  10.058  &lt; 2e-16 ***\ngenderMale                  -0.209714   0.138860  -1.510    0.131    \nsmoking_statusSmoker         0.877283   0.139874   6.272 3.57e-10 ***\ndiabetes_statusNon-Diabetic -0.779280   0.141301  -5.515 3.49e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1383.5  on 997  degrees of freedom\nResidual deviance: 1205.4  on 993  degrees of freedom\nAIC: 1215.4\n\nNumber of Fisher Scoring iterations: 4\n\n\nAge, smoking status, and diabetes status are statistically significant associated with TB in this model4. However, the gender again does not appear to be statistically significant, as the p-value is above the conventional significance level.\n\nmodel5 &lt;- glm(tb_status ~ age + gender + smoking_status + diabetes_status + urban_rural_status,\n                      data = tb_data, family = \"binomial\")\nsummary(model5)\n\n\nCall:\nglm(formula = tb_status ~ age + gender + smoking_status + diabetes_status + \n    urban_rural_status, family = \"binomial\", data = tb_data)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                 -2.384925   0.273729  -8.713  &lt; 2e-16 ***\nage                          0.055037   0.005444  10.110  &lt; 2e-16 ***\ngenderMale                  -0.193101   0.139444  -1.385   0.1661    \nsmoking_statusSmoker         0.869065   0.140283   6.195 5.82e-10 ***\ndiabetes_statusNon-Diabetic -0.780349   0.141733  -5.506 3.68e-08 ***\nurban_rural_statusUrban      0.329746   0.140109   2.353   0.0186 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1383.5  on 997  degrees of freedom\nResidual deviance: 1199.9  on 992  degrees of freedom\nAIC: 1211.9\n\nNumber of Fisher Scoring iterations: 4\n\n\nAge, smoking status, diabetes status, and urban/rural status are statistically significant associated with TB in model5. However,again the gender variable does not appear to be statistically significant, as the p-value is above the conventional significance level."
  },
  {
    "objectID": "data-exercise/data-exercise.html#conclusion",
    "href": "data-exercise/data-exercise.html#conclusion",
    "title": "Data Exercise",
    "section": "Conclusion",
    "text": "Conclusion\nUsing Akaike Information Criterion for model selection. Model 5 has the lowest AIC (1231.2), suggesting it provides a better trade-off between goodness of fit and simplicity. The inclusion of additional variables (gender, urban/rural status) doesn’t necessarily improve model fit, as indicated by AIC and residual deviance."
  },
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Patrick’s data analysis portfolio.",
    "section": "",
    "text": "```html\n\n\nWelcome to Patrick’s data analysis portfolio.\nPlease use the Menu Bar above to look around. Have fun!"
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#visualization",
    "href": "fitting-exercise/fitting-exercise.html#visualization",
    "title": "Fitting Exercise",
    "section": "Visualization",
    "text": "Visualization\n\n#Summary table for all variables\nsummary_data &lt;- summary(fdata[, c(\"Y\", \"DOSE\", \"AGE\", \"SEX\", \"RACE\", \"WT\", \"HT\")])\n\n\n# Scatterplot between outcome(Y) and AGE\nggplot(fdata, aes(x = AGE, y = Y)) +\n  geom_point() +\n  labs(x = \"Age\", y = \"Total Drug (Y)\", title = \"Scatterplot: Total Drug vs Age\")\n\n\n\n\n\n\n\n\nAccording to the scatter I don’t see any meaningful pattern.\n\n# Boxplot between Y and DOSE\nggplot(fdata, aes(x = as.factor(DOSE), y = Y, fill = factor(DOSE))) +\n  geom_boxplot() +\n  labs(x = \"Dose\", y = \"Total Drug (Y)\", title = \"Boxplot: Total Drug vs Dose\")\n\n\n\n\n\n\n\n\n\nggplot(fdata, aes(x = as.factor(SEX), y = Y, fill = factor(SEX))) +\n  geom_boxplot() +\n  labs(x = \"SEX\", y = \"Total Drug (Y)\", title = \"Boxplot: Total Drug vs SEX\")\n\n\n\n\n\n\n\n\n\n# Boxplot between Y and RACE\nggplot(fdata, aes(x = as.factor(RACE), y = Y, fill = factor(RACE))) +\n  geom_boxplot() +\n  labs(x = \"RACE\", y = \"Total Drug (Y)\", title = \"Boxplot: Total Drug vs RACE\")\n\n\n\n\n\n\n\n\n\nggplot(fdata, aes(x = AGE)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\") +\n  labs(x = \"AGE\", y = \"Frequency\", title = \"Distribution of AGE\")\n\n\n\n\n\n\n\n\n\nggplot(fdata, aes(x = Y)) +\n  geom_histogram(bins = 20, fill = \"blue\", color = \"black\") +\n  labs(x = \"Total drug\", y = \"Frequency\", title = \"Distribution of Total drug\")\n\n\n\n\n\n\n\n\nNow we shall do a correlation plot to visually inspect the relationships between variables and identify patterns or correlations.\n\n# Pair/correlation plot\ncorrelation_matrix &lt;- cor(fdata[, c(\"DOSE\", \"AGE\", \"WT\", \"HT\")])\ncorrplot(correlation_matrix, method = \"circle\")\n\n\n\n\n\n\n\n\nAccording to the plot there is a high correlation between Total drug(Y) and Dose."
  },
  {
    "objectID": "fitting-exercise/fitting-exercise.html#model-fitting",
    "href": "fitting-exercise/fitting-exercise.html#model-fitting",
    "title": "Fitting Exercise",
    "section": "Model fitting",
    "text": "Model fitting\n\nWe shall fit a linear model to the continuous outcome (Y) using the main predictor of interest, which we’ll assume here to be DOSE and 2. Fit a linear model to the continuous outcome (Y) using all predictors. For both models, compute RMSE and R-squared and print them out.\n\n\n# Fit a linear model using the main predictor of interest (DOSE)\n\nlin_mod &lt;- linear_reg() %&gt;% set_engine(\"lm\")\nlinear_model &lt;- lin_mod %&gt;% fit(Y ~ DOSE, data = fdata)\n\n\n# Fit a linear model using all predictors\nlinear_model_all &lt;- lin_mod %&gt;% fit(Y ~ ., data = fdata)\n\n\n# Compute the RMSE and R squared for model 1\nmetrics_1 &lt;- linear_model %&gt;% \n  predict(fdata) %&gt;% \n  bind_cols(fdata) %&gt;% \n  metrics(truth = Y, estimate = .pred)\n\n\n# Compute the RMSE and R squared for model 2\nmetrics_2 &lt;- linear_model_all %&gt;% \n  predict(fdata) %&gt;% \n  bind_cols(fdata) %&gt;% \n  metrics(truth = Y, estimate = .pred)\n\n\n# Print the results\nprint(metrics_1)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     666.   \n2 rsq     standard       0.516\n3 mae     standard     517.   \n\nprint(metrics_2)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     591.   \n2 rsq     standard       0.619\n3 mae     standard     444.   \n\n\n\nLinear model with main predictor (DOSE):\nThe linear model with DOSE as the main predictor yielded an RMSE of 666.4618, indicating that on average, the model’s predictions deviated from the actual values by about 666 units. The R-squared value of 0.5156 suggests a moderate level of explanatory power for DOSE alone (though R-squared doesn’t directly translate to a percentage of variance explained).\n\n\nLinear model with all predictors:\nThe model with all predictors resulted in a lower RMSE of 590.8534, a reduction of 11.3% compared to the model with DOSE alone. This suggests that including additional predictors improved the model’s predictive accuracy. The R-squared value increased to 0.6193, indicating the model explains a larger portion of the variance in the outcome variable compared to the single-predictor model.\n\n\nComments and Thoughts:\nWhile both models show some predictive ability, there’s room for improvement. Including all predictors led to a noticeable decrease in RMSE. Further exploration is recommended to develop a more accurate and reliable model. This could involve exploring:\n\n\nInteraction terms:\nAre there interactions between predictors that could influence the outcome?\n\n\nFeature engineering:\nCan we create new features from existing data to capture more complex relationships?\n\n\nModel selection techniques:\nIdentifying the most important predictors using techniques like LASSO regression could improve interpretability and potentially performance. By exploring these avenues, we can potentially develop a more robust linear model for predicting the outcome variable.\nNow we shall SEX as the outcome of interest (that doesn’t make too much scientific sense, but we want to practice fitting both continuous and categorical outcomes).\n\n## ---- fit-data-logistic --------\n# fit the logistic models with SEX as outcome \n# first model has only DOSE as predictor\n# second model has all variables as predictors\nlog_mod &lt;- logistic_reg() %&gt;% set_engine(\"glm\")\nlogmod1 &lt;- log_mod %&gt;% fit(SEX ~ DOSE, data = fdata)\nlogmod2 &lt;- log_mod %&gt;% fit(SEX ~ ., data = fdata)\n\n\n# Compute the accuracy and AUC for model 1\nlogmod1_acc &lt;- logmod1 %&gt;% \n  predict(fdata) %&gt;% \n  bind_cols(fdata) %&gt;% \n  metrics(truth = SEX, estimate = .pred_class) %&gt;% \n  filter(.metric == \"accuracy\") \n\n\nlogmod1_auc &lt;-  logmod1 %&gt;%\n  predict(fdata, type = \"prob\") %&gt;%\n  bind_cols(fdata) %&gt;%\n  roc_auc(truth = SEX, .pred_1)\n\n\n# Compute the accuracy and AUC for model 2\nlogmod2_acc &lt;- logmod2 %&gt;% \n  predict(fdata) %&gt;% \n  bind_cols(fdata) %&gt;% \n  metrics(truth = SEX, estimate = .pred_class) %&gt;% \n  filter(.metric %in% c(\"accuracy\"))\n\n\nlogmod2_auc &lt;-  logmod2 %&gt;%\n  predict(fdata, type = \"prob\") %&gt;%\n  bind_cols(fdata) %&gt;%\n  roc_auc(truth = SEX, .pred_1)\n\n\n# Print the results\nprint(logmod1_acc)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.867\n\nprint(logmod2_acc)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.942\n\nprint(logmod1_auc)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.592\n\nprint(logmod2_auc)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.980\n\n\n\n\nLogistic models were used to predict SEX based on various factors.\nThe model with DOSE as the sole predictor performed well, with an accuracy of 86.7% and a ROC-AUC score of 0.5919 (suggesting only slightly better than random chance at distinguishing between the two SEX classes).\nIn contrast, the model that included all predictors achieved a significantly higher accuracy of 94.17 (7.5% improvement) and a much stronger ROC-AUC score of 97.96. This score indicates excellent discriminative power, meaning the model can effectively rank positive instances (correctly predicted SEX) higher than negative ones (incorrectly predicted SEX).\n\n\nComments and Thoughts\nIncluding all available predictors significantly improved the model’s ability to predict SEX. However, further exploration is recommended to develop an even more accurate and reliable model. This could involve:\n\n\nFeature Engineering:\nCreating new features based on existing data to potentially capture more complex relationships.\n\n\nVariable Selection:\nIdentifying the most important predictors using statistical techniques to potentially improve model interpretability and performance.\n\n\nExploring alternative models:\nInvestigating other classification algorithms besides logistic regression to see if they might yield even better results. By exploring these avenues, we can potentially develop a more robust model for predicting SEX.\n\n\n\nrngseed = 1234\nset.seed(rngseed)\n#spliting data into 75% train and 25% test set\ndata_split &lt;- initial_split(fdata, prop = 0.75) \ndata_train &lt;- training(data_split)\ndata_test &lt;- testing(data_split)"
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at C:/Users/chaoh/Desktop/UGA Courses/4_Spring 2024/EPID 8060E/MADA/patrickkaggwa-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  character                1     \n  factor                   1     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Educ                  0             1   7  13     0        4          0\n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n3 age                   0             1  41.7 13.4  22  34  45  54   56 ▃▂▂▂▇\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\nb1&lt;-mydata %&gt;%\n  ggplot(mapping = aes(x = `Educ`, y = Height, fill = `Educ`)) +\n  geom_boxplot() +\n  scale_fill_manual(values = c(\"College\" = \"#1f78b4\", \"High school\" = \"#33a02c\", \"Graduate\" = \"#e31a1c\", \"Undergraduate\" = \"#ff7f00\")) +\n  theme_minimal() +\n  labs(x = \"Education levels\", y = \"Height\") +\n  ggtitle(\"Boxplot of Education Levels by Height\") +\n  theme(plot.title = element_text(hjust = 0.5))  # Adjust title alignment\nb1\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"education-Height-stratified.png\")\nggsave(filename = figure_file, plot=b1) \n\nSaving 7 x 5 in image\n\n\n\ns1 &lt;- ggplot(mydata, aes(x = Weight, y = age)) +\n  geom_point() +\n  stat_smooth(method = \"glm\", formula = y ~ x) +\n  ggtitle(\"Scatterplot of Weight vs Age\") +\n  labs(x = \"Weight\", y = \"Age\")\ns1\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"Weight-Age-stratified.png\")\nggsave(filename = figure_file, plot=s1) \n\nSaving 7 x 5 in image\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at C:/Users/chaoh/Desktop/UGA Courses/4_Spring 2024/EPID 8060E/MADA/patrickkaggwa-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 5 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`        \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                   \n1 Height          height in centimeters                 numeric value &gt;0 or NA  \n2 Weight          weight in kilograms                   numeric value &gt;0 or NA  \n3 Gender          identified gender (male/female/other) M/F/O/NA                \n4 age             age in complete years                 numeric value &gt;0 or NA  \n5 educ            level of education                    Highschool,college, und…\n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 5\n$ Height &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"155\", …\n$ Weight &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"F\", \"M…\n$ age    &lt;dbl&gt; 50, 45, 65, 56, 36, 54, 34, 38, 30, 42, 44, 22, 54, 22\n$ Educ   &lt;chr&gt; \"College\", \"High school\", \"Undergraduate\", \"Graduate\", \"College…\n\nsummary(rawdata)\n\n    Height              Weight          Gender               age       \n Length:14          Min.   :  45.0   Length:14          Min.   :22.00  \n Class :character   1st Qu.:  55.0   Class :character   1st Qu.:34.50  \n Mode  :character   Median :  70.0   Mode  :character   Median :43.00  \n                    Mean   : 602.7                      Mean   :42.29  \n                    3rd Qu.:  90.0                      3rd Qu.:53.00  \n                    Max.   :7000.0                      Max.   :65.00  \n                    NA's   :1                                          \n     Educ          \n Length:14         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nhead(rawdata)\n\n# A tibble: 6 × 5\n  Height Weight Gender   age Educ         \n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;        \n1 180        80 M         50 College      \n2 175        70 O         45 High school  \n3 sixty      60 F         65 Undergraduate\n4 178        76 F         56 Graduate     \n5 192        90 NA        36 College      \n6 6          55 F         54 High school  \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nEduc\n0\n1\n7\n13\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55.0\n70\n90\n7000\n▇▁▁▁▁\n\n\nage\n0\n1.00\n42.29\n12.86\n22\n34.5\n43\n53\n65\n▆▆▆▇▂\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nEduc\n0\n1\n7\n13\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nage\n0\n1.00\n40.54\n11.52\n22\n34.00\n42\n50\n56\n▃▃▆▃▇\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nEduc\n0\n1\n7\n13\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nage\n0\n1.00\n40.54\n11.52\n22\n34.00\n42\n50\n56\n▃▃▆▃▇\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nEduc\n0\n1\n7\n13\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\nage\n0\n1\n40.09\n12.56\n22\n32.0\n38\n52\n56\n▃▃▃▂▇\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nEduc\n0\n1\n7\n13\n0\n4\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\nage\n0\n1\n40.09\n12.56\n22\n32.0\n38\n52\n56\n▃▃▃▂▇\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nEduc\n0\n1\n7\n13\n0\n4\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nage\n0\n1\n41.67\n13.40\n22\n34\n45\n54\n56\n▃▂▂▂▇\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at C:/Users/chaoh/Desktop/UGA Courses/4_Spring 2024/EPID 8060E/MADA/patrickkaggwa-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 3 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`      \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                 \n1 Height          height in centimeters                 numeric value &gt;0 or NA\n2 Weight          weight in kilograms                   numeric value &gt;0 or NA\n3 Gender          identified gender (male/female/other) M/F/O/NA              \n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 3\n$ Height &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"155\", …\n$ Weight &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"F\", \"M…\n\nsummary(rawdata)\n\n    Height              Weight          Gender         \n Length:14          Min.   :  45.0   Length:14         \n Class :character   1st Qu.:  55.0   Class :character  \n Mode  :character   Median :  70.0   Mode  :character  \n                    Mean   : 602.7                     \n                    3rd Qu.:  90.0                     \n                    Max.   :7000.0                     \n                    NA's   :1                          \n\nhead(rawdata)\n\n# A tibble: 6 × 3\n  Height Weight Gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 180        80 M     \n2 175        70 O     \n3 sixty      60 F     \n4 178        76 F     \n5 192        90 NA    \n6 6          55 F     \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55\n70\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Patrick Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains a simple made-up data-set in an Excel file.\nIt contains the variables Height, Weight and Gender of a few imaginary individuals.\nThe dataset purposefully contains some faulty entries that need to be cleaned.\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  }
]